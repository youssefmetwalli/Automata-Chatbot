{
    "ask_automata": "<b>Automata Theory</b> is a branch of theoretical computer science that involves designing abstract machines, and solving computational problems that can be solved through the usage of these machines.",
    "ask_automaton": "You can represent an automaton using a 5-tuple (Q, ∑, δ, q0, F), where:<br>Q is a finite set of states.<br>∑ is a finite set of symbols, called the alphabet of the automaton.<br>δ is the transition function.<br>q0 is the initial state from where any input is processed (q0 ∈ Q).<br>F is a set of final state/states of Q (F ⊆ Q).",
    "ask_alphabet": "An <b>alphabet</b> is any finite set of symbols.<br>Example − ∑ = {a, b, c, d} is an alphabet set where ‘a’, ‘b’, ‘c’, and ‘d’ are symbols.",
    "ask_string": "A <b>string</b> is a finite sequence of symbols taken from ∑.<br>Example − ‘aabacd’ is a valid string on the alphabet set ∑ = {a, b, c, d}.<br><br>A string S accepted by automaton (DFA/NDFA) can be represented as δ*(q0, S) ∈ F.<br>A string S' not accepted by automaton (DFA/NDFA) can be represented as δ*(q0, S′) ∉ F.",
    "ask_string_length": "The length of the string is the number of symbols in a string denoted <b>|S|</b>.<br>Examples: If S = ‘babca’, |S|= 5.",
    "ask_empty_string": "An <b>empty string</b> is a string where its length <b>|S|</b> is equal to 0.<br>Denoted using λ or ε.",
    "ask_language": "A <b>language</b> refers to a set of strings composed of symbols from a given alphabet.<br>Example:<br><br>A language that can take all possible strings of length 2 over the alphabet ∑ = {a, b} is L = {aa, ab, ba, bb}.<br><br>The language L accepted by automaton (DFA/NDFA) can be represented as {S | S ∈ ∑* and δ*(q0, S) ∈ F}.<br>The language L' not accepted by automaton (DFA/NDFA) can be represented as {S | S ∈ ∑* and δ*(q0, S) ∉ F}.",
    "ask_kleene": "The <b>Kleene closure</b> is the infinite set of all possible strings with all possible lengths over ∑ excluding λ.<br>Example - If ∑ = {a, b}, ∑+ = {a, b, aa, ab, ba, bb, ……}",
    "ask_transition_function": "Denoted by δ. A <b>transition function</b> is a function where δ: Q × ∑ → Q.<br>It defines the rules for moving from one state to another based on the current state and the input symbol being read.",
    "ask_ndfa": "A <b>NDFA</b> is an automaton where, for a given input symbol, the machine can move to any combination of the states present in the machine. In other words, the exact state to which the machine would move can't be determined.",
    "ask_dfa": "A <b>DFA</b> is an automaton that consists of a finite set of states, and a transition function that can map each state and input symbol to a single next state.",
    "ask_dfa_vs_ndfa": "<b>DFA</b>: The transition from a state is to a single particular next state for each input symbol. Hence it is called deterministic. Empty string transitions are not seen in DFA. Backtracking is allowed in DFA. Requires more space. A string is accepted by a DFA, if it transits to a final state. <b>NDFA</b>: The transition from a state can be to multiple next states for each input symbol. Hence it is called non-deterministic. NDFA permits empty string transitions. In NDFA, backtracking is not always possible. Requires less space. A string is accepted by a NDFA, if at least one of all possible transitions ends in a final state.",
    "ask_ndfa_to_dfa": "1) Create a table from the given NDFA. \n2) Create a blank table under possible input alphabets for the DFA. \n Mark the start state for both the NDFA and the DFA. \n 4) Trace the combination of States {Q0, Q1,... , Qn} for each possible input alphabet. \n5) Keep applying step 4 whenever you generate a new DFA state under the input alphabet columns. \n6) The states that have the corresponding final states of the NDFA are the final states for the NFA. ",
    "ask_dfa_minimization": "You can follow these steps to acheive DFA Minimization:\n 1) Draw a table for all pairs for all states (Qi, Qj)\n 2) Examine every state pair (Qi, Qj) in the given DFA where Qi ∈ F and Qj ∉ F or vice versa, then mark them. (F is the set of final states)\n 3) Repeat step 2) until there aren't any states left to mark.\n  *it's worth noting that if there's an unmarked pair (Qi, Qj),you should mark it if the pair {δ (Qi, A), δ (Qi, A)} is marked for some input alphabet. 4) Combine the remaining unmarked pairs(Qi, Qj), and turn them into a single state in the reduced DFA. ",
    "ask_mealy_machine": "A Mealy Machine is a Finite State Machine whose output depends on both the present state, and the present input.\n It can be described as a 6 tuple 6 tuple (Q, ∑, O, δ, X, q0):\n - Q is the finite set of states. \n -∑ is the input alphabet. \n -O is the output alphabet. \n -δ resembles the input transition function where δ: Q × ∑ → Q \n -X resembles the output transition function where <b>X: Q × ∑ → O</b>  \n -q0 is the initial state.",
    "ask_moore_machine": "A Moore Machine is a Finite State Machine whose output depends solely on the present state.\n It can be described as a 6 tuple 6 tuple (Q, ∑, O, δ, X, q0):\n - Q is the finite set of states. \n -∑ is the input alphabet. \n -O is the output alphabet. \n -δ resembles the input transition function where δ: Q × ∑ → Q \n -X resembles the output transition function where <b>X: Q → O</b>  \n -q0 is the initial state.",
    "ask_grammar": "A Grammar <b>G</b> is a formal system that descraibes the syntax of a Language. \n A grammar can be considered as a 4-tuple (N, T, S, P): \n - N is a set of variables(non-terminal symbols). \n - T or ∑ is a set of Terminal Symbols. \n - S resembles a special variable refered to as the Start symbol where S ∈ N. \n P is the production rule(s) for Terminals and Non-terminals. \n Example: G= ({S, A, B}, {a, b}, S, {S → AB, A → a, B → b}) \n -S,A,B ∈ N (non terminal symbols). \n - a, b are terminal symbols. \n S is the start symbol, and S ∈ N. \n  S → AB, A → a, B → b is the production rule. ",
    "ask_derivation_grammar": "You can derive strings from other strings using the production rules in a given grammar. For example: grammar G = ({S, A}, {a, b}, S, {S → aAb, aA → aaAb, A → ε } ) \n S ⇒ aAb  (rule S → aAb ) \n ⇒ aaAbb (using rule aA → aAb) \n ⇒ aaaAbbb (using rule aA → aaAb) \n ⇒ aaabbb (using rule A → ε)", 
    "ask_language_from_grammar": "The set of all the strings that can be derived from a grammar is called the language generated from a grammar <b>G</b>",
    "ask_chomsky_classification": "<b>Chomsky Classification</b> classifies grammars into four types:<br><br><b>Type 0: Recursively Enumerable Languages</b><br>- <b>Grammar:</b> Unrestricted Grammar<br>- <b>Automaton:</b> Turing Machine<br>- <b>Description:</b> These languages can be recognized by a Turing machine. Rules have the form α → β, where α and β are any strings with at least one non-terminal on the left.<br><br><b>Type 1: Context-Sensitive Languages</b><br>- <b>Grammar:</b> Context-Sensitive Grammar<br>- <b>Automaton:</b> Linear Bounded Automaton (LBA)<br>- <b>Description:</b> These grammars have rules αAβ → αγβ, with the string on the right at least as long as the string on the left.<br><br><b>Type 2: Context-Free Languages</b><br>- <b>Grammar:</b> Context-Free Grammar (CFG)<br>- <b>Automaton:</b> Pushdown Automaton (PDA)<br>- <b>Description:</b> These grammars have rules A → γ, where A is a non-terminal and γ is a string. Recognized by pushdown automata.<br><br><b>Type 3: Regular Languages</b><br>- <b>Grammar:</b> Regular Grammar<br>- <b>Automaton:</b> Finite Automaton (DFA/NFA)<br>- <b>Description:</b> These grammars have rules A → aB or A → a, and can be recognized by finite automata.",
    "ask_regex": "A <b>regular expression</b> defines a search pattern. Examples of RE: \n - (0 + 10*) : L = { 0, 1, 10, 100, 1000, 10000, … } \n -(0*10*) : L = {ε, 0, 1, 01} \n -(aa)*(bb)*b : L = {b, aab, aabbb, aabbbbb, aaaab, aaaabbb, …………..} (any string with an even number of a's followed by an odd number of b's) ",
    "ask_regular_sets": "Sets that represent the value of a regular expression are called <b> Regular Sets </b>",
    "ask_construct_fa_from_re": "<b>Constructing a Finite Automaton from a Regular Expression</b>:\n\n<b>Step-by-Step Process:</b>\n1. <b>Convert RE to NFA:</b>\n   - Break down the regular expression into its basic components (e.g., concatenation, union, Kleene star).\n   - Construct an NFA for each basic component.\n   - Combine the NFAs to form a single NFA for the entire regular expression.\n\n2. <b>Basic Conversions:</b>\n   - For a single character 'a': Create an NFA with two states and a transition labeled 'a'.\n   - For the empty string 'ε': Create an NFA with a single state that is both the start and accepting state.\n   - For union (R1 + R2): Create a new start state with ε-transitions to the start states of the NFAs for R1 and R2. Create a new accepting state with ε-transitions from the accepting states of the NFAs for R1 and R2.\n   - For concatenation (R1R2): Connect the accepting state of the NFA for R1 to the start state of the NFA for R2 with an ε-transition.\n   - For Kleene star (R*): Create a new start state with an ε-transition to the start state of the NFA for R and an ε-transition to a new accepting state. Add an ε-transition from the accepting state of the NFA for R back to its start state and to the new accepting state.\n\n3. <b>Convert NFA to DFA:</b>\n   - Apply the subset construction algorithm to convert the NFA to an equivalent DFA.\n   - Create states in the DFA corresponding to sets of states in the NFA.\n   - Define transitions in the DFA based on the transitions in the NFA.\n\n4. <b>Minimize the DFA (Optional):</b>\n   - Remove unreachable states.\n   - Merge equivalent states to create the minimal DFA.\n\n<b>Example:</b>\nConsider the regular expression (a+b)*:\n   - Construct NFAs for 'a' and 'b'.\n   - Combine them using union and Kleene star operations to form the NFA for (a+b)*.\n   - Convert the NFA to an equivalent DFA.\n   - (Optional) Minimize the DFA to obtain the simplest form.",
    "ask_ardens_theorem": "<b>Arden's Theorem</b>:\n\n<b>Theorem Statement:</b>\nLet P and Q be two regular expressions over an alphabet ∑. The equation R = Q + RP has a unique solution given by R = QP*.\n\n<b>Explanation:</b>\nArden's Theorem provides a method to solve linear equations involving regular expressions. It states that if R is a regular expression that satisfies the equation R = Q + RP, then the unique solution for R is given by R = QP*.\n\n<b>Steps to Apply Arden's Theorem:</b>\n1. Identify the equation in the form R = Q + RP.\n2. Apply Arden's Theorem to find R = QP*.\n\n<b>Example:</b>\nGiven the equation R = a + Rb, the solution is R = a(b)*.",
    "ask_dfa_complement": "<b>DFA Complement</b> is the complement of a language recognized by a DFA is the set of strings over the alphabet that are not accepted by the DFA.\n\n<b>Steps to Construct the Complement of a DFA:</b>\n1. <b>Given:</b> A DFA D = (Q, Σ, δ, q0, F) where:\n   - Q: Finite set of states\n   - Σ: Alphabet\n   - δ: Transition function\n   - q0: Initial state\n   - F: Set of accepting (final) states\n\n2. <b>Construct the Complement DFA:</b>\n   - Keep the same set of states (Q).\n   - Keep the same alphabet (Σ).\n   - Keep the same transition function (δ).\n   - Keep the same initial state (q0).\n   - Change the set of accepting states to its complement with respect to Q. That is, the new set of accepting states is Q \\ F.\n\n<b>Example:</b>\nConsider a DFA D with the following components:\n   - Q = {q0, q1, q2}\n   - Σ = {a, b}\n   - δ: \n     δ(q0, a) = q1\n     δ(q0, b) = q0\n     δ(q1, a) = q2\n     δ(q1, b) = q0\n     δ(q2, a) = q2\n     δ(q2, b) = q2\n   - q0 is the initial state.\n   - F = {q2} (accepting states)\n\nTo construct the complement DFA D':\n   - Q' = Q = {q0, q1, q2}\n   - Σ' = Σ = {a, b}\n   - δ' = δ (same transition function)\n   - q0' = q0 (same initial state)\n   - F' = Q \\ F = {q0, q1} (complement of the accepting states)\n\n<b>Result:</b>\nThe DFA D' will accept all strings that the original DFA D does not accept and reject all strings that the original DFA D accepts.",
    "ask_cfg_introduction": "A Context Free Grammar is a formal grammar that can generate all strings in a given language. It is defined by a 4-tuple (V, Σ, R, S) where:\n1. <b>V</b>: Finite set of variables (non-terminals).\n2. <b>Σ</b>: Finite set of terminal symbols (alphabet).\n3. <b>R</b>: Finite set of production rules.\n4. <b>S</b>: Start variable.\n\n<b>Production Rules:</b>\nRules have the form A → α, where A is a non-terminal and α is a string of terminals and/or non-terminals.\n\n<b>Example:</b>\nCFG G = ({S, A}, {a, b}, R, S) with rules:\n1. S → aSb\n2. S → A\n3. A → ε\n\n<b>Derivation:</b>\nA sequence of steps to generate a string. Example for 'aabb':\n1. S ⇒ aSb\n2. ⇒ aaSbb\n3. ⇒ aaAbb\n4. ⇒ aabb\n\n<b>Applications:</b>\nCFGs are used in programming languages, compilers, and natural language processing.",
    "ask_cfl_closure_property": "Closure properties describe how languages combine to form new languages within the same class. CFLs are closed under some operations but not all.\n\n<b>Closed Under:</b>\n1. <b>Union:</b>\nIf L1 and L2 are CFLs, then L1 ∪ L2 is also a CFL.\n2. <b>Concatenation:</b>\nIf L1 and L2 are CFLs, then L1L2 is also a CFL.\n3. <b>Kleene Star:</b>\nIf L is a CFL, then L* (zero or more concatenations of L) is also a CFL.\n4. <b>Reversal:</b>\nIf L is a CFL, then the reversal of L is also a CFL.\n\n<b>Not Closed Under:</b>\n1. <b>Intersection:</b>\nThe intersection of two CFLs may not be a CFL.\n2. <b>Complement:</b>\nThe complement of a CFL may not be a CFL.\n\n<b>Example:</b>\nFor CFLs L1 = {a^n b^n | n ≥ 0} and L2 = {b^n a^n | n ≥ 0}:\n- L1 ∪ L2 is a CFL.\n- L1L2 is a CFL.\n- L1* is a CFL.\n- The intersection of L1 and L2 is not a CFL.",
    "ask_cfg_ambiguity": "A context-free grammar (CFG) is said to be ambiguous if there exists at least one string that can be generated by the grammar in more than one way, resulting in different parse trees or derivations.\n\n<b>Parse Trees:</b>\nA parse tree visually represents the structure of a string derived from a CFG. If a string has more than one parse tree, the grammar is ambiguous.\n\n<b>Example:</b>\nConsider the CFG with rules:\n1. E → E + E\n2. E → E * E\n3. E → (E)\n4. E → id\n\nThe string 'id + id * id' can be derived in two ways:\n1. E → E + E → id + E → id + E * E → id + id * id\n2. E → E * E → E + E * E → id + E * E → id + id * id\n\nEach derivation corresponds to a different parse tree, indicating the grammar is ambiguous.\n\n<b>Implications:</b>\nAmbiguity in grammars can lead to different interpretations of the same string, which is undesirable in programming languages and compilers.\n\n<b>Resolving Ambiguity:</b>\nAmbiguity can sometimes be resolved by rewriting the grammar or using additional rules to enforce a specific interpretation.",
    "ask_cfg_simplification": "Simplification of a Context-Free Grammar (CFG) involves reducing the grammar to its simplest form without changing the language it generates.\n\n<b>Steps:</b>\n1. <b>Remove Useless Symbols:</b>\nEliminate symbols that do not contribute to deriving any terminal string.\n2. <b>Remove Unreachable Symbols:</b>\nEliminate symbols that cannot be reached from the start symbol.\n3. <b>Remove ε-Productions:</b>\nEliminate productions that generate the empty string (except when necessary).\n4. <b>Remove Unit Productions:</b>\nEliminate productions where a non-terminal maps directly to another non-terminal.\n\n<b>Example:</b>\nFor CFG G with productions:\nS → AB | C\nA → aA | ε\nB → b\nC → c\n\n<b>Remove Useless Symbols:</b>\nAll symbols are useful.\n\n<b>Remove Unreachable Symbols:</b>\nAll symbols are reachable.\n\n<b>Remove ε-Productions:</b>\nModify A → aA | ε to A → aA and adjust other productions accordingly.\n\n<b>Remove Unit Productions:</b>\nS → AB | C becomes S → AB | c\n\n<b>Resulting CFG:</b>\nS → AB | c\nA → aA | a\nB → b",
    "ask_chomsky_normal_form": "A Context-Free Grammar (CFG) is in Chomsky Normal Form (CNF) if every production rule is of the form:\n1. A → BC\n2. A → a\n3. S → ε (only if the language includes the empty string)\nwhere A, B, and C are non-terminal symbols, a is a terminal symbol, and S is the start symbol.\n\n<b>Steps to Convert a CFG to CNF:</b>\n1. <b>Remove ε-Productions:</b>\nEliminate productions that produce the empty string (except for the start symbol if necessary).\n2. <b>Remove Unit Productions:</b>\nEliminate productions where a non-terminal maps directly to another non-terminal.\n3. <b>Remove Useless Symbols:</b>\nEliminate symbols that do not contribute to generating terminal strings.\n4. <b>Convert to Binary Productions:</b>\nConvert productions with more than two non-terminals on the right-hand side into binary productions using additional non-terminal symbols.\n\n<b>Example:</b>\nFor CFG G with productions:\nS → ASA | aB\nA → B | S\nB → b | ε\n\n<b>Remove ε-Productions:</b>\nAdjust rules to remove ε:\nS → ASA | aB | AS | SA | a\nA → B | S\nB → b\n\n<b>Remove Unit Productions:</b>\nEliminate unit productions:\nS → ASA | aB | AS | SA | a\nA → b | ASA | aB | AS | SA | a\n\n<b>Convert to Binary Productions:</b>\nIntroduce new non-terminals to ensure binary productions:\nS → AX | aB | AS | SA | a\nA → b | AX | AS | SA | a\nX → SA\n\n<b>Resulting CNF:</b>\nS → AX | aB | AS | SA | a\nA → b | AX | AS | SA | a\nX → SA",
    "ask_greibach_normal_form": "A CFG is in greibach normal form(GNF) if every production is of the form A → aα, where A is a non-terminal, a is a terminal, and α is a string of non-terminals.\n\n<b>Steps to Convert to GNF:</b>\n1. <b>Remove ε-Productions:</b> Eliminate productions that produce ε.\n2. <b>Remove Unit Productions:</b> Eliminate productions where a non-terminal maps directly to another non-terminal.\n3. <b>Ensure Proper Form:</b> Ensure each production starts with a terminal followed by non-terminals.\n\n<b>Example:</b>\nGiven CFG:\nS → AB | a\nA → b | S\nB → c\n\n<b>Remove ε-Productions:</b> Not needed here.\n\n<b>Remove Unit Productions:</b>\nS → AB | a\nA → b | AB | a\nB → c\n\n<b>Ensure Proper Form:</b>\nS → a | aB\nA → b | aB\nB → c\n\n<b>Resulting GNF:</b>\nS → a | aB\nA → b | aB\nB → c",
    "ask_pumping_lemma_cfg": "<b>Pumping Lemma for CFG</b>:\n\n<b>Statement:</b> For any context-free language L, there exists a number p (the pumping length) such that any string s in L with length at least p can be decomposed as s = uvwxy, where:\n1. |vwx| ≤ p\n2. |vx| ≥ 1\n3. For all i ≥ 0, the string u(v^i)w(x^i)y is in L\n\n<b>Purpose:</b> To prove that a given language is not context-free by demonstrating that no such p can be found that satisfies the lemma's conditions.\n\n<b>Usage:</b>\n1. Assume L is a context-free language.\n2. Let p be the pumping length given by the lemma.\n3. Choose a string s in L with |s| ≥ p.\n4. Show that for any possible decomposition of s = uvwxy, at least one of the conditions is violated for some i ≥ 0.\n\n<b>Example:</b>\nTo show L = {a^n b^n c^n | n ≥ 0} is not context-free:\n1. Assume L is context-free with pumping length p.\n2. Choose s = a^p b^p c^p.\n3. No matter how s is divided into uvwxy, at least one of the conditions will be violated for some i, proving L is not context-free.",
    "ask_pumping_lemma": "<b>Pumping Lemma</b> is a property of regular languages that provides a way to prove that certain languages aren't regular.\n\n<b>Theorem Statement:</b>\nIf L is a regular language, then there exists a constant n (the pumping length) such that any string s in L with a length of at least n can be divided into three parts, s = xyz, satisfying the following conditions:\n1. For each i ≥ 0, the string xy^i z is in L.\n2. |y| > 0 (y is not empty).\n3. |xy| ≤ n.\n\n<b>Steps to Use the Pumping Lemma:</b>\n1. Assume that L is a regular language.\n2. Let n be the pumping length given by the Pumping Lemma.\n3. Choose a string s in L such that |s| ≥ n.\n4. Divide s into three parts, s = xyz, satisfying the conditions of the Pumping Lemma.\n5. Show that there exists an i such that xy^i z is not in L, leading to a contradiction.\n6. Conclude that L is not a regular language.\n\n<b>Example:</b>\nConsider the language L = {a^n b^n | n ≥ 0}.\n1. Assume L is regular and let n be the pumping length.\n2. Choose s = a^n b^n which is in L and |s| = 2n.\n3. Divide s into xyz where |xy| ≤ n and |y| > 0.\n   - y must consist only of 'a's because |xy| ≤ n.\n4. Pump y: Let i = 2, then xy^2z = a^(n+|y|) b^n.\n5. The resulting string has more 'a's than 'b's and is not in L.\n6. This contradicts the assumption that L is regular, hence L is not a regular language.",
    "pushdown_automata_introduction": "A <b>Pushdown Automaton (PDA)</b> is a computational model that consists of a finite state machine combined with a stack. The stack provides additional memory beyond the finite amount available in the state machine.\n\nA PDA can be formally described as a 7-tuple (Q, ∑, S, δ, q0, I, F):\n\n<b>Q</b> is a finite set of states.\n2. <b>∑</b> is the input alphabet.\n3. <b>S</b> is a finite set of stack symbols (stack alphabet).\n4. <b>δ</b> is the transition function: Q × (∑ ∪ {ε}) × S → Q × S*.\n5. <b>q0</b> is the initial state (q0 ∈ Q).\n6. <b>I</b> is the initial stack symbol (I ∈ S).\n7. <b>F</b> is a set of accepting states (F ⊆ Q).\n\nThe transition function δ defines how the PDA moves between states, reads input symbols, and manipulates the stack. \n\n<b>Usage:</b> PDAs are used to recognize context-free languages. They are more powerful than finite automata but less powerful than Turing machines.",
    "pda_context_free_grammar": "<b>PDA & Context-Free Grammar</b>:\n\n<b>Relationship:</b> Every context-free grammar (CFG) can be transformed into an equivalent pushdown automaton (PDA) that recognizes the same language, and vice versa.\n\n<b>Conversion:</b>\n1. <b>From CFG to PDA:</b> Construct a PDA that simulates the leftmost derivation of the CFG.\n2. <b>From PDA to CFG:</b> Create a CFG that generates the same language recognized by the PDA.\n\n<b>Example:</b> A CFG with production rules S → aSb | ε can be converted to a PDA that pushes 'a' onto the stack for each 'a' read, pops 'a' for each 'b' read, and accepts when the stack is empty.",
    "pda_parsing": "<b>Pushdown Automata & Parsing</b>:\n\n<b>Role in Parsing:</b> PDAs play a crucial role in parsing, particularly for context-free languages. They can be used to construct parsers that check whether a given string belongs to the language generated by a grammar.\n\n<b>Types of Parsers:</b>\n1. <b>Top-Down Parsers:</b> Start from the start symbol and attempt to derive the input string.\n2. <b>Bottom-Up Parsers:</b> Start from the input string and attempt to reduce it to the start symbol.\n\n<b>Example:</b> LL(1) and LR(0) parsers use PDAs to manage the parsing stack and handle state transitions during the parsing process.",
    "ask_turing_machine": "<b>Turing Machine Introduction</b>:\n\nA <b>Turing Machine</b> is a theoretical computational model introduced by Alan Turing. It consists of an infinite tape, a tape head that can read and write symbols on the tape, and a finite set of states.\n\n<b>A TM can be considered as a 7-tuple (Q, X, ∑, δ, q0, B, F) where:</b>\n1. Q is a finite set of states\n2. X is the tape alphabet\n3. ∑ is the input alphabet\n4. δ is a transition function; δ : Q × X → Q × X × {Left_shift, Right_shift}\n5. q0 is the initial state\n6. B is the blank symbol\n7. F is the set of final states\n\n<b>Usage:</b> Turing Machines are used to define the concept of algorithm and computability. They can simulate the logic of any computer algorithm and are fundamental in the theory of computation.",
    "accepted_language_decided_language": "A language is accepted by a Turing Machine if, for every string in the language, the machine enters an accepting state. The machine may not halt for strings not in the language.\n\n<b>Decided Language:</b> A language is decided (or recognized) by a Turing Machine if the machine halts on every input string, entering an accepting state for strings in the language and a rejecting state for strings not in the language.",
    "multi_tape_turing_machine": "A <b>Multi-tape Turing Machine</b> is a variant of the standard Turing Machine that has multiple tapes, each with its own tape head. The transition function can read and write symbols on all tapes simultaneously and move each tape head independently.\n\nA Multi-tape Turing machine can be formally described as a 6-tuple (Q, X, B, δ, q0, F) where:\n\n1. Q is a finite set of states\n2. X is the tape alphabet\n3. B is the blank symbol\n4. δ is a relation on states and symbols where δ: Q × Xk → Q × (X × {Left_shift, Right_shift, No_shift})k where there is k number of tapes\n5. q0 is the initial state\n6. F is the set of final states\n\n<b>Advantages:</b> Multi-tape Turing Machines can be more efficient than single-tape machines for certain tasks, as they can perform multiple operations in parallel.\n\n<b>Equivalence:</b> Despite their increased efficiency, multi-tape Turing Machines are equivalent in computational power to single-tape Turing Machines. Any computation performed by a multi-tape machine can be simulated by a single-tape machine.",
    "multi_track_turing_machine": "A <b>Multi-track Turing Machine</b> is a variant of the standard Turing Machine where the tape is divided into multiple tracks, and the tape head reads and writes on all tracks simultaneously. Each cell of the tape contains a tuple of symbols, one from each track.\n\nA Multi-track Turing machine can be formally described as a 6-tuple (Q, X, ∑, δ, q0, F) where:\n\n1. Q is a finite set of states\n2. X is the tape alphabet\n3. ∑ is the input alphabet\n4. δ is a relation on states and symbols where δ(Qi, [a1, a2, a3,....]) = (Qj, [b1, b2, b3,....], Left_shift or Right_shift)\n5. q0 is the initial state\n6. F is the set of final states\n\n<b>Usage:</b> Multi-track Turing Machines are useful for representing more complex data structures and performing parallel processing on the tracks.\n\n<b>Equivalence:</b> Like multi-tape machines, multi-track Turing Machines are equivalent in computational power to single-tape Turing Machines. Any computation performed by a multi-track machine can be simulated by a single-track machine.",
    "non_deterministic_turing_machine": "A <b>Non-Deterministic Turing Machine (NDTM)</b> is a variant of the standard Turing Machine where, for a given state and tape symbol, the machine can have multiple possible next moves. It is a theoretical model used to explore the limits of computability and complexity.\n\nA non-deterministic Turing machine can be formally defined as a 6-tuple (Q, X, ∑, δ, q0, B, F) where:\n\n1. Q is a finite set of states\n2. X is the tape alphabet\n3. ∑ is the input alphabet\n4. δ is a transition function; δ : Q × X → P(Q × X × {Left_shift, Right_shift})\n5. q0 is the initial state\n6. B is the blank symbol\n7. F is the set of final states\n\n<b>Non-determinism:</b> At each step, the NDTM can choose from multiple possible transitions, which means it can explore many computational paths simultaneously. This feature is useful for solving certain types of problems more efficiently in theory.\n\n<b>Equivalence:</b> While NDTMs can be more efficient in terms of theoretical exploration of computational paths, they are equivalent in computational power to deterministic Turing Machines. Any computation that can be done by an NDTM can also be done by a deterministic Turing Machine.",
    "semi_infinite_tape_turing_machine": "A <b>Semi-Infinite Tape Turing Machine</b> is a variant of the standard Turing Machine where the tape is infinite in one direction (usually to the right) and has a fixed left end. The machine operates similarly to a standard Turing Machine but cannot move the tape head to the left of the leftmost cell.\n\n<b>Usage:</b> Semi-infinite tape Turing Machines are useful for certain theoretical investigations and simplifying the analysis of algorithms.\n\n<b>Equivalence:</b> Semi-infinite tape Turing Machines are equivalent in computational power to standard (infinite tape) Turing Machines. Any computation performed by a semi-infinite tape machine can be simulated by a standard Turing Machine.",
    "linear_bounded_automata": "A <b>Linear Bounded Automaton (LBA)</b> is a restricted form of a Turing Machine where the tape is limited to the portion that contains the input string plus a constant amount of extra space. A LBA can be defined as an 8-tuple (Q, X, ∑, q0, ML, MR, δ, F) where −\n\n1. Q is a finite set of states\n2. X is the tape alphabet\n3. ∑ is the input alphabet\n4. q0 is the initial state\n5. ML is the left end marker\n6. MR is the right end marker where MR ≠ ML\n7. δ is a transition function which maps each pair (state, tape symbol) to (state, tape symbol, Constant ‘c’) where c can be 0 or +1 or -1\n8. F is the set of final states\n\nLBAs are used to recognize context-sensitive languages, which are more powerful than context-free languages but less powerful than general recursive languages.",
    "language_decidability": "<b>Language Decidability</b> refers to whether a problem can be solved by an algorithm in a finite amount of time. A language is <b>decidable</b> if there exists a Turing Machine that accepts all strings in the language and rejects all strings not in the language, halting on all inputs. Decidable languages are also known as <b>recursive languages</b>.",  
    "undecidable_languages": "An <b>undecidable language</b> is a language for which no Turing Machine can decide membership for all possible input strings. This means there is no algorithm that can determine for every string whether it belongs to the language or not. Examples of undecidable problems include the <b>halting problem</b> and the problem of determining whether a given Turing Machine accepts a particular input.",    
    "turing_machine_halting_problem": "The <b>Turing Machine Halting Problem</b> is a famous example of an undecidable problem. It asks whether a given Turing Machine will halt on a given input or just continue to run forever. Alan Turing proved that there is no general algorithm that can solve the halting problem for all possible Turing Machine-input pairs. This result has profound implications for the limits of computation and what can be automated or decided algorithmically.",
    "rice_theorem": "<b>Rice's Theorem</b> states that any non-trivial property of the language recognized by a Turing Machine is undecidable. A property of the language is non-trivial if it holds for some but not all Turing Machines. This means that for any interesting or meaningful property of the languages that Turing Machines recognize (such as emptiness, finiteness, regularity, context-freeness, etc.), it is impossible to construct a general algorithm that decides whether an arbitrary Turing Machine has that property.",
    "post_correspondence_problem": "The <b>Post Correspondence Problem (PCP)</b> is a well-known undecidable problem in the theory of computation. Given two lists of strings, A = [a1, a2, ..., an] and B = [b1, b2, ..., bn], the problem asks if there exists a sequence of indices i1, i2, ..., ik such that the concatenation of the corresponding strings from the two lists are equal, i.e., ai1 ai2 ... aik = bi1 bi2 ... bik. Despite its simple formulation, PCP is undecidable, meaning there is no algorithm that can solve all instances of the problem.",
    "unknown": "My bad I don't understand, may you ask something else?"
}